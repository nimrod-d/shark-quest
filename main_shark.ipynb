{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8288df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\nimrod\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b44dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c870aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shark_clean as sh\n",
    "\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "shark_df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7b7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df = shark_df.drop(['pdf', 'href formula','href','Case Number','Case Number.1','original order','Unnamed: 21','Unnamed: 22','Unnamed: 11','Source'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85a4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df = shark_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48518778",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df = shark_df.dropna(subset=['Country', 'State', 'Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5049fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df.columns = shark_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9d2a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hawaii', 'Florida', 'California', 'South Carolina',\n",
       "       'North Carolina', 'New York', 'New Jersey', 'Samoa', 'Louisiana',\n",
       "       'Mississippi', 'Noirth Carolina', 'Georgia', 'Alabama', 'Texas',\n",
       "       'Maryland', 'Maui', 'Oregon', 'Franklin County, Florida',\n",
       "       'Virgin Islands', 'Maine', 'Bahamas', 'Delaware', 'Guam',\n",
       "       'Cayman Islands', 'Rhode Island', 'Massachusetts', 'Washington',\n",
       "       'Puerto Rico', 'Virginia', 'US Virgin Islands', 'Kentucky',\n",
       "       'New Mexico', 'South Carolina ', 'Alaska', 'Missouri',\n",
       "       'North Carolina ', 'Florida ', 'Connecticut', 'Pennsylvania',\n",
       "       'Illinois', 'Wake Island', ' North Carolina', ' New Jersey',\n",
       "       'New York ', 'CUBA'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standarizing the states in USA\n",
    "\n",
    "usa_states = shark_df.loc[shark_df['country'] == 'USA', 'state']\n",
    "usa_states_unique = usa_states.unique()\n",
    "usa_states_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99022d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hawaii', 'florida', 'california', 'south carolina',\n",
       "       'north carolina', 'new york', 'new jersey', 'samoa', 'louisiana',\n",
       "       'mississippi', 'georgia', 'alabama', 'texas', 'maryland', 'oregon',\n",
       "       'virgin islands', 'maine', 'bahamas', 'delaware', 'guam',\n",
       "       'cayman islands', 'rhode island', 'massachusetts', 'washington',\n",
       "       'puerto rico', 'virginia', 'us virgin islands', 'kentucky',\n",
       "       'new mexico', 'alaska', 'missouri', 'connecticut', 'pennsylvania',\n",
       "       'illinois', 'wake island'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove cuba\n",
    "\n",
    "row_index_cuba = shark_df.index[shark_df['state'].str.lower() == 'cuba'].tolist()\n",
    "\n",
    "# Update 'country' and 'state' in the identified row\n",
    "shark_df.loc[row_index_cuba, 'country'] = 'CUBA'\n",
    "shark_df.loc[row_index_cuba, 'state'] = ''\n",
    "\n",
    "# Standardize the state names in USA\n",
    "shark_df['state'] = shark_df['state'].str.strip().str.lower().replace({\n",
    "    'noirth carolina': 'north carolina',\n",
    "    'maui': 'hawaii',\n",
    "    'franklin county, florida': 'florida',\n",
    "    'cuba': ''\n",
    "})\n",
    "\n",
    "# Check the unique values in 'state' for USA after replacement\n",
    "usa_states = shark_df.loc[shark_df['country'] == 'USA', 'state']\n",
    "usa_states_unique_after = usa_states.unique()\n",
    "usa_states_unique_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9085ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## performing cleaning using functions from above cell to create activity_grouped and updating type column\n",
    "\n",
    "\n",
    "shark_df['activity_grouped'] = shark_df['activity'].apply(sh.clean_activity)\n",
    "shark_df['type'] = shark_df['type'].apply(sh.clean_type)\n",
    "shark_df['species '] = shark_df['species '].apply(sh.clean_species)\n",
    "shark_df['fatal_bool'] = shark_df['injury'].apply(sh.clean_fatal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb3713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'sex' column to M, F and UNDEFINED\n",
    "shark_df.sex = shark_df.sex.fillna('Undefined')\n",
    "shark_df.sex = shark_df.sex.apply(lambda sex:sex.strip().upper() if isinstance(sex,str) else sex)\n",
    "shark_df.sex = shark_df.sex.replace(['LLI'],['UNDEFINED'])\n",
    "\n",
    "# clean 'name' column to fill nan as 'Unknown'\n",
    "shark_df.name = shark_df.name.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04dcf6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>injury</th>\n",
       "      <th>time</th>\n",
       "      <th>species</th>\n",
       "      <th>activity_grouped</th>\n",
       "      <th>fatal_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 Dec-2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>Baby Beach, Maui</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Jason Carter</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>11h12</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>water_sport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>05 Nov-2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>florida</td>\n",
       "      <td>Juno Beach, Palm Beach County</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Steven Reinhardt</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>Lacerations to right forearm</td>\n",
       "      <td>10h30</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>swimming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25 Oct 2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>Puaâ€™ena Point,  Haleiwa, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>Bite to right thigh</td>\n",
       "      <td>15h05</td>\n",
       "      <td>Tiger Shark</td>\n",
       "      <td>water_sport</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15 Oct 2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>Hanalei Bay, Kauai</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Kevin Kanehe</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>Left leg and hand injured</td>\n",
       "      <td>16h00</td>\n",
       "      <td>Tiger Shark</td>\n",
       "      <td>water_sport</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13 Oct-2023</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>california</td>\n",
       "      <td>Linda Mar, Pacific State Beach, San Mateo County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>52</td>\n",
       "      <td>Minor linjury to left lower leg</td>\n",
       "      <td>15h45</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>water_sport</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>Before 1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>florida</td>\n",
       "      <td>Palm Beach, Palm Beach County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Horton Chase</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abrasions &amp; bruises hip to ankle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>Before 1921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>florida</td>\n",
       "      <td>Gadsden Point, Tampa Bay</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>James Kelley</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-inch lacerations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>fishing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918</th>\n",
       "      <td>Before 17-Jul-1916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>north carolina</td>\n",
       "      <td>Somewhere between Hatteras and Beaufort</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>\"youthful male\"</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lost leg\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>swimming</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6922</th>\n",
       "      <td>Circa 1862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>hawaii</td>\n",
       "      <td>Puna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A \"chiefess\"</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankle bitten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>north carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>swimming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date    year        type country           state  \\\n",
       "2            30 Dec-2023  2023.0  Unprovoked     USA          hawaii   \n",
       "16           05 Nov-2023  2023.0  Unprovoked     USA         florida   \n",
       "21           25 Oct 2023  2023.0  Unprovoked     USA          hawaii   \n",
       "25           15 Oct 2023  2023.0  Unprovoked     USA          hawaii   \n",
       "26           13 Oct-2023  2023.0  Unprovoked     USA      california   \n",
       "...                  ...     ...         ...     ...             ...   \n",
       "6879         Before 1958     0.0  Unprovoked     USA         florida   \n",
       "6913         Before 1921     0.0  Unprovoked     USA         florida   \n",
       "6918  Before 17-Jul-1916     0.0  Unprovoked     USA  north carolina   \n",
       "6922          Circa 1862     0.0  Unprovoked     USA          hawaii   \n",
       "6929           1900-1905     0.0  Unprovoked     USA  north carolina   \n",
       "\n",
       "                                              location  activity  \\\n",
       "2                                     Baby Beach, Maui   Surfing   \n",
       "16                       Juno Beach, Palm Beach County  Swimming   \n",
       "21                       Puaâ€™ena Point,  Haleiwa, Oahu   Surfing   \n",
       "25                                  Hanalei Bay, Kauai   Surfing   \n",
       "26    Linda Mar, Pacific State Beach, San Mateo County   Surfing   \n",
       "...                                                ...       ...   \n",
       "6879                     Palm Beach, Palm Beach County  Standing   \n",
       "6913                          Gadsden Point, Tampa Bay   Fishing   \n",
       "6918           Somewhere between Hatteras and Beaufort  Swimming   \n",
       "6922                                              Puna       NaN   \n",
       "6929                                    Ocracoke Inlet  Swimming   \n",
       "\n",
       "                       name sex  age                            injury   time  \\\n",
       "2              Jason Carter   M   39                             FATAL  11h12   \n",
       "16         Steven Reinhardt   M   66      Lacerations to right forearm  10h30   \n",
       "21                     male   M   30               Bite to right thigh  15h05   \n",
       "25             Kevin Kanehe   M   50         Left leg and hand injured  16h00   \n",
       "26                     male   M   52  Minor linjury to left lower leg   15h45   \n",
       "...                     ...  ..  ...                               ...    ...   \n",
       "6879           Horton Chase   M  NaN  Abrasions & bruises hip to ankle    NaN   \n",
       "6913           James Kelley   M  NaN                2-inch lacerations    NaN   \n",
       "6918        \"youthful male\"   M  NaN                        \"Lost leg\"    NaN   \n",
       "6922           A \"chiefess\"   F  NaN                      Ankle bitten    NaN   \n",
       "6929  Coast Guard personnel   M  NaN                             FATAL    NaN   \n",
       "\n",
       "         species  activity_grouped  fatal_bool  \n",
       "2         Unknown      water_sport           1  \n",
       "16        Unknown         swimming           0  \n",
       "21    Tiger Shark      water_sport           0  \n",
       "25    Tiger Shark      water_sport           0  \n",
       "26        Unknown      water_sport           0  \n",
       "...           ...              ...         ...  \n",
       "6879      Unknown           others           0  \n",
       "6913      Unknown          fishing           0  \n",
       "6918      Unknown         swimming           0  \n",
       "6922      Unknown           others           0  \n",
       "6929      Unknown         swimming           1  \n",
       "\n",
       "[2476 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shark_df_us = shark_df[shark_df['country']=='USA']\n",
    "shark_df_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33659460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\427528797.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us['year'] = shark_df_us['year'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Change all strings to integers\n",
    "shark_df_us['year'] = shark_df_us['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b69d40f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Get the unique value of these cells\n",
    "result = shark_df_us['year'].unique()\n",
    "smaller_than_4 = [value for value in result if len(str(value)) < 4]\n",
    "print(smaller_than_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ca737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\3655955125.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us['year'] = shark_df_us['year'].replace(item, shark_df_us.year.mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# Replace these values with the Mode of the column year\n",
    "for item in smaller_than_4:\n",
    "    shark_df_us['year'] = shark_df_us['year'].replace(item, shark_df_us.year.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb433288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013,\n",
       "       2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002,\n",
       "       2001, 2000, 1999, 1998, 1997, 1996, 1995, 1994, 1993, 1992, 1991,\n",
       "       1990, 1989, 1988, 1987, 1986, 1985, 1984, 1983, 1982, 1981, 1980,\n",
       "       1979, 1978, 1977, 1976, 1975, 1974, 1973, 1972, 1971, 1970, 1969,\n",
       "       1968, 1967, 1966, 1965, 1964, 1963, 1962, 1961, 1960, 1959, 1958,\n",
       "       1957, 1956, 1955, 1954, 1953, 1952, 1951, 1950, 1949, 1948, 1947,\n",
       "       1945, 1944, 1943, 1941, 1940, 1939, 1938, 1937, 1936, 1935, 1934,\n",
       "       1933, 1932, 1931, 1930, 1929, 1928, 1927, 1926, 1925, 1924, 1923,\n",
       "       1922, 1920, 1919, 1918, 1917, 1916, 1915, 1914, 1913, 1912, 1911,\n",
       "       1910, 1909, 1908, 1907, 1906, 1905, 1904, 1903, 1902, 1901, 1900,\n",
       "       1899, 1898, 1897, 1896, 1895, 1894, 1892, 1891, 1890, 1889, 1887,\n",
       "       1886, 1885, 1884, 1883, 1882, 1881, 1880, 1879, 1878, 1876, 1874,\n",
       "       1873, 1872, 1871, 1870, 1866, 1865, 1864, 1863, 1862, 1860, 1859,\n",
       "       1858, 1857, 1855, 1853, 1852, 1851, 1849, 1848, 1847, 1845, 1842,\n",
       "       1840, 1837, 1830, 1829, 1828, 1817, 1816, 1810, 1805, 1803, 1780,\n",
       "       1779, 1640, 1642, 1000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check again for irregularities\n",
    "shark_df_us['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "438f8b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\497128711.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us[\"date\"] = shark_df_us[\"date\"].str.replace('  ', '-').str.replace(' ', '-').str.replace('--', '-').str.replace('Reported', '').str.replace('`', '').str.replace('.', '').str.strip()\n",
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\497128711.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: '-'.join(filter(lambda x: x and len(x) <= 10, date_list)))\n",
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\497128711.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: '-'.join(x.split('-')) if pd.notna(x) and len(x.split('-')) > 1 else x)\n",
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\497128711.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: date_list[:1] + [date_list[1][:3]] + date_list[2:] if len(date_list) == 3 else date_list).apply(lambda date_list: '-'.join(date_list) if date_list else '')\n",
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\497128711.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: ['01', 'Jan'] + date_list if len(date_list) == 1 and len(date_list[0]) == 4 else date_list).apply(lambda date_list: '-'.join(date_list) if date_list else '')\n",
      "C:\\Users\\Nimrod\\AppData\\Local\\Temp\\ipykernel_36428\\497128711.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: ['01'] + date_list if len(date_list) == 2 else date_list).apply(lambda date_list: '-'.join(date_list) if date_list else '')\n"
     ]
    }
   ],
   "source": [
    "# format the Dates in to the same format\n",
    "shark_df_us[\"date\"] = shark_df_us[\"date\"].str.replace('  ', '-').str.replace(' ', '-').str.replace('--', '-').str.replace('Reported', '').str.replace('`', '').str.replace('.', '').str.strip()\n",
    "shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: '-'.join(filter(lambda x: x and len(x) <= 10, date_list)))\n",
    "shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: '-'.join(x.split('-')) if pd.notna(x) and len(x.split('-')) > 1 else x)\n",
    "shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: date_list[:1] + [date_list[1][:3]] + date_list[2:] if len(date_list) == 3 else date_list).apply(lambda date_list: '-'.join(date_list) if date_list else '')\n",
    "shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: ['01', 'Jan'] + date_list if len(date_list) == 1 and len(date_list[0]) == 4 else date_list).apply(lambda date_list: '-'.join(date_list) if date_list else '')\n",
    "shark_df_us[\"date\"] = shark_df_us[\"date\"].apply(lambda x: x.split('-') if pd.notna(x) else []).apply(lambda date_list: ['01'] + date_list if len(date_list) == 2 else date_list).apply(lambda date_list: '-'.join(date_list) if date_list else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5469b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df_us.to_csv('C:\\\\Users\\\\Nimrod\\\\Documents\\\\GitHub\\\\2nd_try_iron_repo\\\\Quests\\\\shark_df_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1273f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c89745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
